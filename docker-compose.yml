version: '3.8'

services:
  # ----------------------------------------
  # 1. BASE DE DATOS POSTGRES
  # ----------------------------------------
  postgres:
    image: postgres:15
    container_name: db-postgres
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password123
    ports:
      - "5432:5432"
    volumes:
      - db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      retries: 5
      start_period: 5s

  # ----------------------------------------
  # 2. BASE DE DATOS MONGO
  # ----------------------------------------
  mongo:
    image: mongo:6.0
    container_name: db-mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 5s

  # ----------------------------------------
  # 3. OLLAMA (IA Generativa - AUTO PULL)
  # ----------------------------------------
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-service
    ports:
      - "11434:11434"
    volumes:
      - ollama_storage:/root/.ollama
    # --- TRUCO PARA AUTO-DESCARGAR EL MODELO ---
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        # 1. Iniciar el servidor en segundo plano
        /bin/ollama serve &
        pid=$!

        # 2. Esperar a que el servidor responda
        echo "⏳ Esperando a que Ollama inicie..."
        while [ "$(ollama list | grep 'NAME')" == "" ]; do
          sleep 1
        done

        # 3. Descargar el modelo automáticamente
        echo "⬇️  Verificando/Descargando modelo llama3.1:8b..."
        ollama pull llama3.1:8b
        
        echo "✅ Modelo listo!"

        # 4. Mantener el proceso vivo
        wait $pid

  # ----------------------------------------
  # 4. MICROSERVICIO IA (Python)
  # ----------------------------------------
  ml-api:
    build: ./BackendIE/ml/ml-api
    container_name: ia-service
    ports:
      - "8000:8000"
    restart: on-failure

  # ----------------------------------------
  # 5. BACKEND (Spring Boot)
  # ----------------------------------------
  backend:
    build: ./BackendIE
    container_name: backend-app
    ports:
      - "8080:8080"
    environment:
      # --- VARIABLES QUE ARREGLAN EL PROBLEMA ---
      # Estas variables nativas de Spring sobrescriben cualquier properties
      SPRING_DATA_MONGODB_URI: mongodb://mongo:27017/auditoria_db
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/postgres
      DB_POSTGRES_HOST: postgres
      DB_POSTGRES_PORT: 5432
      DB_POSTGRES_NAME: postgres
      DB_POSTGRES_USER: postgres
      DB_PASSWORD: password123 
      SPRING_JPA_HIBERNATE_DDL_AUTO: update
      DB_MONGO_HOST: mongo
      DB_MONGO_PORT: 27017
      DB_MONGO_NAME: auditoria_db
      ML_API_URL: http://ml-api:8000/predict
      OLLAMA_BASE_URL: http://ollama:11434
      TOKEN_SECRET: UcpcTUB8LdxR08M4DXc4x/ivUzrA2g2xz/lGPWTs+cdM4jNJLwMW4A==
      FRONTEND_URL: http://localhost:3000
      CORS_ALLOWED_ORIGINS: http://localhost:3000
      EMAIL_USERNAME: duvanvch12@gmail.com
      EMAIL_PASSWORD: maui ybwq wsuu mnbr
      EMAIL_FROM: duvanvch12@gmail.com
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy # <-- ¡LA CORRECCIÓN MÁGICA!
      ml-api:
        condition: service_started

  # ----------------------------------------
  # 6. FRONTEND (Next.js)
  # ----------------------------------------
  frontend:
    build:
      context: ./Frontend_2
      args:
        NEXT_PUBLIC_API_URL: http://localhost:8080
    container_name: frontend-app
    ports:
      - "3000:3000"
    depends_on:
      - backend

volumes:
  db-data:
  mongo-data:
  ollama_storage: